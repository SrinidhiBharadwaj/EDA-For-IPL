{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38964bitee0e28a584b0444399bbb6a87c33016f",
   "display_name": "Python 3.8.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Using beautiful soup to parse html of a url from web\n",
    "Find the tables.\n",
    "Since the tables don't have a specific class or id and the column -\n",
    "    headers may vary I manualy found the index of the tables that -\n",
    "    display auction information\n",
    "Find the Table headers and place them in a list\n",
    "'''\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_2008_Indian_Premier_League_auctions_and_personnel_signings\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "table = soup.find_all(\"table\")\n",
    "headers = []\n",
    "for th in table[2].find_all('th'):\n",
    "    title = th.text.strip()\n",
    "    headers.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a pandas DataFrame using the table headers as columns\n",
    "Place all the table rows from selected table in the parsed html in to the DataFrame\n",
    "Remove any spacing or special characters \n",
    "Remove unnecessary columns\n",
    "Change the Name of the columns to be same as other tables\n",
    "Change the type of columns as needed\n",
    "Convert the money as needed\n",
    "Add Year column\n",
    "'''\n",
    "theTable08 = pd.DataFrame(columns = headers)\n",
    "for tr in table[2].find_all('tr')[1:]:\n",
    "    rowData = tr.find_all('td')\n",
    "    row = [elem.text.strip() for elem in rowData]\n",
    "    length = len(theTable08)\n",
    "    theTable08.loc[length] = row\n",
    "theTable08 = theTable08.drop(theTable08.columns[[0, 1, 3, 4, 5]], axis = 1)\n",
    "theTable08 = theTable08.rename(columns={\"Name\": \"Player\", \"Auctioned Price(in US$ thousands)\": \"Amount\"})\n",
    "theTable08[\"Amount\"] = pd.to_numeric(theTable08[\"Amount\"])\n",
    "theTable08['Amount'] = theTable08[\"Amount\"].apply(lambda x: x*81525)\n",
    "theTable08[\"Year\"] = 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_2009_Indian_Premier_League_personnel_changes\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "print(page.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find_all(\"table\")\n",
    "headers = []\n",
    "for th in table[7].find_all('th'):\n",
    "    title = th.text.strip()\n",
    "    headers.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "theTable09 = pd.DataFrame(columns = headers)\n",
    "for tr in table[7].find_all('tr')[1:]:\n",
    "    rowData = tr.find_all('td')\n",
    "    row = [elem.text.strip().replace('$','').replace(',','') for elem in rowData]\n",
    "    length = len(theTable09)\n",
    "    theTable09.loc[length] = row\n",
    "theTable09 = theTable09.drop(theTable09.columns[[0, 4]], axis = 1)\n",
    "theTable09 = theTable09.rename(columns={\"Winning bid\": \"Amount\"})\n",
    "theTable09[\"Amount\"] = pd.to_numeric(theTable09[\"Amount\"])\n",
    "theTable09['Amount'] = theTable09[\"Amount\"].apply(lambda x: x*81.53)\n",
    "theTable09[\"Year\"] = 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_2010_Indian_Premier_League_personnel_changes\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "print(page.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find_all(\"table\")\n",
    "headers = []\n",
    "for th in table[0].find_all('th'):\n",
    "    title = th.text.strip()\n",
    "    headers.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "theTable10 = pd.DataFrame(columns = headers)\n",
    "for tr in table[0].find_all('tr')[1:]:\n",
    "    rowData = tr.find_all('td')\n",
    "    row = [elem.text.strip().replace('$','').replace(',','') for elem in rowData]\n",
    "    length = len(theTable10)\n",
    "    theTable10.loc[length] = row\n",
    "theTable10 = theTable10.drop(theTable10.columns[[3]], axis = 1)\n",
    "theTable10 = theTable10.rename(columns={\"Franchise\": \"Team\", \"Sold price (USD)\": \"Amount\"})\n",
    "theTable10[\"Amount\"] = pd.to_numeric(theTable10[\"Amount\"])\n",
    "theTable10['Amount'] = theTable10[\"Amount\"].apply(lambda x: x*81.53)\n",
    "theTable10[\"Year\"] = 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_2011_Indian_Premier_League_personnel_changes\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "print(page.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find_all(\"table\")\n",
    "headers = []\n",
    "for th in table[2].find_all('th'):\n",
    "    title = th.text.strip()\n",
    "    headers.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "theTable11 = pd.DataFrame(columns = headers)\n",
    "for tr in table[2].find_all('tr')[1:]:\n",
    "    rowData = tr.find_all('td')\n",
    "    row = [elem.text.strip().replace('$','').replace(',','') for elem in rowData]\n",
    "    length = len(theTable11)\n",
    "    theTable11.loc[length] = row\n",
    "theTable11 = theTable11.drop(theTable11.columns[[0, 4]], axis = 1)\n",
    "theTable11 = theTable11.rename(columns={\"Winning bid\": \"Amount\"})\n",
    "theTable11[\"Amount\"] = pd.to_numeric(theTable11[\"Amount\"])\n",
    "theTable11['Amount'] = theTable11[\"Amount\"].apply(lambda x: x*81.53)\n",
    "theTable11[\"Year\"] = 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_2012_Indian_Premier_League_personnel_changes\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "print(page.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find_all(\"table\")\n",
    "headers = []\n",
    "for th in table[9].find_all('th'):\n",
    "    title = th.text.strip()\n",
    "    headers.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "theTable12 = pd.DataFrame(columns = headers)\n",
    "for tr in table[9].find_all('tr')[1:]:\n",
    "    rowData = tr.find_all('td')\n",
    "    row = [elem.text.strip().replace('$','').replace(',','') for elem in rowData]\n",
    "    length = len(theTable12)\n",
    "    theTable12.loc[length] = row\n",
    "theTable12 = theTable12.drop(theTable12.columns[[0, 3]], axis = 1)\n",
    "theTable12 = theTable12.rename(columns={\"Winning bid\": \"Amount\"})\n",
    "theTable12[\"Amount\"] = pd.to_numeric(theTable12[\"Amount\"])\n",
    "theTable12['Amount'] = theTable12[\"Amount\"].apply(lambda x: x*81.53)\n",
    "theTable12[\"Year\"] = 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Combine all the DataFrames from 2008 to 2012\n",
    "Read in csv to DataFrames\n",
    "Remove unnecessary columns\n",
    "Combine DataFrames to include data from 2008 to 2022\n",
    "Write to a new csv file\n",
    "'''\n",
    "theTable08To12 = pd.concat([theTable08, theTable09, theTable10, theTable11, theTable12])\n",
    "theTable13_22 = pd.read_csv ('/Users/sepehr/Documents/ECE143/Final/IPLPlayerAuctionData13-22.csv')\n",
    "theTable13_22 = theTable13_22.drop(theTable13_22.columns[[1, 5]], axis = 1)\n",
    "theTable = pd.concat([theTable08To12, theTable13_22])\n",
    "thePath = os.getcwd() + '/IPL Player Auction 08-22.csv'\n",
    "theTable.to_csv(thePath, index=False)"
   ]
  }
 ]
}